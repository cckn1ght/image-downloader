### 一些说明

1. 前端代码在 `src` 里面，只对一个打包 zip 的库 `jszip` 进行了依赖。自己仿 axios 的接口格式实现了一个 naive 的基于 XHR 的 HTTP 请求方法，在 `/src/requestlib.js` 里面。还有一些辅助方法在 `/src/utils.js` 里面。因为只有一个页面，就直接写在 `/src/App.js` 里面了。
2. 后端代码在 `backend`。主要文件是 `/backend/server.js`。也是只对一个打包 zip 的库`archiver` 进行了依赖。仿造 express 的接口格式做了一个可以添加各个类型 HTTP 请求以及文件请求的 router，在 `backend/controller.js` 里面。生成 zip 文件并发送给 response 的逻辑在 `backend/utils.js`。
3. 基于可能的两种业务场景，我这边做了两个下载 zip 打包文件的实现。第一种是假设前端得到的是未经压缩的无损的图片，在这种场景下，既然前端已经拿到过一次图片，就没有必要再从后端拿到需要的压缩包了，可以直接从前端压缩下载。这样对于服务器端来说性能是最好的。第二种场景是假设前端得到的只是压缩过的缩略图，那么只能再从后端压缩原始图片并传输 zip 文件。还有个思路是如果原始图片 host 在 CDN 上面，可以回到第一种情况，从前端拿原始图片并且压缩。网页上有两个按钮，分别对应这两种实现。
4. 在后端压缩的情况下，增加了一个缓存压缩过的文件的功能。具体实现是根据前端请求的图片数组，将所有图片名称合并起来，生成一个 hash 值，这个值作为 zip 压缩包的文件名，第一次生成的时候会对文件名进行缓存，如果下次有另一个请求生成了同样的 hash 值，那我直接取出对应的压缩包发送就行了，不需要再去取对应的图片再压缩。可以节省 cpu 时间。不过这个特性理论上会浪费大量的硬盘空间，但是对于目前的计算设备来说，硬盘一般都不是问题。
5. 目前的后端是比较 naive 的，为了提高整体性能，我会在服务器启动的时候将所有图片加载入内存，这样的话在高并发的请求下硬盘 IO 不会成为瓶颈。但是显然在图片数据量巨大的情况下，这个功能是没法实现的。数据量大的情况下，问题可能会变得比较复杂，如果还是单机能接受的数据的话，我觉得可以在内存里载入一部分图片，利用类似 LRU 这类算法去控制内存里保留着的图片。数据量再大到一个节点都放不下的时候，就必须使用一些分布式的存储方案，比如 HDFS。但是 HDFS 对类似图片这样的小文件处理地特别慢，可以使用 HBase 做为存储端。
6. 前端 build 之后的文件我已经放到了`/backend`，最终效果可以在 `/backend` 里面运行 `cnpm install` 然后 `node server.js`(或 `npm start`)，访问 `http://localhost:3001` 看到。